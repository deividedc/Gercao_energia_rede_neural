# -*- coding: utf-8 -*-
"""Atividade_8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Rqiks9eUBi9BqzhsjvxSC7_bi7SBK7Yx
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline


from matplotlib.colors import ListedColormap


import tensorflow as tf
import keras
from keras.models import Sequential
from keras.layers import Dense,Activation,Dropout
from keras.callbacks import ModelCheckpoint
from keras.models import load_model
import types
import tempfile
import keras.models
from keras.wrappers.scikit_learn import KerasClassifier
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import roc_curve, auc
# acessa o google drive
from google.colab import drive

#faz conexão com o google drive
drive.mount('/content/drive')

#leitura da base de dados
dataSets = pd.read_csv('/content/drive/My Drive/Datasets/T1.csv')





# Remove coluna (Data/Time da base de dados)
dataSets = dataSets.drop("Date/Time", axis=1)

#renomeando colunas
dataSets = dataSets.rename(columns={'LV ActivePower (kW)': 'Active_power','Wind Speed (m/s)':'Wind_speed','Theoretical_Power_Curve (KWh)': 'Theoretical_power','Wind Direction (°)':'Wind_direction'})
dataSets = dataSets.dropna()

#obtendo informações da base de dados
dataSets.info()

dataSets

#selecionando recursos e eliminando recursos não necessários
datax = np.asarray(dataSets.copy().drop(['Active_power','Theoretical_power'],axis=1).values)

#selecionando o alvo
datay = dataSets.copy()['Active_power'].values

#definindo se tem ou não geração de energia
for i in range(len(datay)):
  if datay[i]==0:
    datay[i]= False
  else:
    datay[i]= True

#plotando grafico de corelação de valores
fig = plt.figure(figsize = (15,15))

sns.heatmap(dataSets.corr(), annot=True,vmax = .8)
plt.show()

#definindo valores para treino, teste e validação
#o modelo é divido em 70% dos valores da base de dados para treio, 15% para teste e 15% para


data_samples = datax.shape[0]
x_train = datax[:int(0.7 * data_samples)]
x_val = datax[int(0.7 * data_samples) : int(0.85 * data_samples)]
x_test = datax[int(0.85 * data_samples) :]

y_train = datay[:int(0.7 * data_samples)]
y_val = datay[int(0.7 * data_samples) : int(0.85 * data_samples)]
y_test = datay[int(0.85 * data_samples) :]

print("Valores para treino: " + str(x_train.shape[0]))
print("Valores para validação: " + str(x_val.shape[0]))
print("Valores para teste: " + str(x_test.shape[0]))

#inicializando o modelo com 5 camadas e definindo o numero de neuronios em cada camada
model1 = keras.Sequential([
    Dense(10,kernel_initializer = 'normal',input_shape = (2,),activation = 'relu'),
    Dense(25,kernel_initializer = 'normal',activation = 'relu'),
    Dense(25,kernel_initializer = 'normal',activation = 'relu'),
    Dense(10,kernel_initializer = 'normal',activation = 'relu'),
    Dense(1,kernel_initializer = 'normal',activation = 'linear')
])

#compilando o modelo 1
model1.compile(
    loss = 'mean_absolute_error',optimizer='adam',metrics=['accuracy'])

model1.summary()

#inicializando o modelo com 5 camadas e definindo o numero de neuronios em cada camada
model2 = keras.Sequential([
    Dense(3,kernel_initializer = 'normal',input_shape = (2,),activation = 'relu'),
    Dense(5,kernel_initializer = 'normal',activation = 'relu'),
    Dense(5,kernel_initializer = 'normal',activation = 'relu'),
    Dense(2,kernel_initializer = 'normal',activation = 'relu'),
    Dense(1,kernel_initializer = 'normal',activation = 'linear')
])

#compilando o modelo 2
model2.compile(
    loss = 'mean_absolute_error',optimizer='adam',metrics=['accuracy'])

model2.summary()

#definindo o número de epocas
epocas = 1000

#realizando o fit do modelo 1
fit1 = model1.fit(x_train,y_train,validation_data=(x_val,y_val),validation_split=0.1,epochs=epocas,verbose=1)

#realizando o fit do modelo 2
fit2 = model2.fit(x_train,y_train,validation_data=(x_val,y_val),validation_split=0.1,epochs=epocas,verbose=1)

#criando função para plotar grafico da perda
def display_training_curves(training1,training2,validation1,validation2,title,subplot):
    if subplot%10 == 1:
        plt.subplots(figsize = (10,10),facecolor='#F0F0F0')
        plt.tight_layout()
    ax = plt.subplot(subplot)
    ax.set_facecolor('#F8F8F8')
    ax.plot(training1)
    ax.plot(training2)
    ax.plot(validation1)
    ax.plot(validation2)
    ax.set_title(title + ' dos Modelos')
    ax.set_ylabel(title)
    ax.set_xlabel('Época')
    ax.legend(['Treino Modelo 1', 'Treino modelo 2', 'Validação Modelo 1', 'Validação Modelo 2'])

#plot da perda do modelo 1
display_training_curves(fit1.history['loss'], fit2.history['loss'],fit1.history['val_loss'],fit2.history['val_loss'], 'Perda', 211)

#plot da acuracia do modelo 1
display_training_curves(fit1.history['accuracy'], fit2.history['accuracy'],fit1.history['val_accuracy'],fit2.history['val_accuracy'], 'Acuracia', 211)

#obter valores da estimativa do modelo
y_pred1 = model1.predict(x_test)
y_pred2 = model2.predict(x_test)

def plot_roc(pred,pred2,y):
    fpr, tpr, _ = roc_curve(y, pred)
    roc_auc = auc(fpr, tpr)

    fpr2, tpr2, _ = roc_curve(y, pred2)
    roc_auc2 = auc(fpr2, tpr2)
    plt.figure()
    plt.figure(figsize=(12,7))
    plt.plot(fpr, tpr, label='Curva de roc modelo1 (area = %0.8f)' % roc_auc)
    plt.plot(fpr2, tpr2, label='Curva de roc modelo2 (area = %0.8f)' % roc_auc2)

    plt.plot([0, 1 ], [0, 1], 'k--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('Falso Positivo')
    plt.ylabel('Verdadeiro Positive')
    plt.title('Características de operação  (ROC)')
    plt.legend(loc="lower right")
    plt.show()

plot_roc(y_pred1,y_pred2,y_test)